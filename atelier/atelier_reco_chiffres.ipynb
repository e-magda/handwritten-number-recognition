{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atelier ML - Reconnaissance de chiffres manuscrits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet atelier, vous allez entra√Æner un mod√®le qui permet de reconnaitre les chiffres √©crits √† la main √† partir du dataset MNIST. Ensuite, vous pourrez int√©grer ce mod√®le dans une application qui permettra √† l'utilisateur de \"dessiner\" un chiffre et d'afficher la pr√©diction.\n",
    "\n",
    "Etapes : \n",
    "*   S√©lection d'un dataset restreint pour entra√Æner votre mod√®le\n",
    "*   Gestion d'un dataset contenant des images en format pixel\n",
    "*   Entrainement d'un mod√®le de Support Vector Machine (SVM)\n",
    "*   Cr√©ation d'un Pipeline\n",
    "*   Sauvegarde d'un mod√®le avec Pickle\n",
    "*   Cr√©ation d'une application Streamlit avec une fonctionnalit√© de dessin (canva)\n",
    "*   Pr√©dictions directement dans l'application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencez par importer le dataset MNIST et comprendre son contenu.\n",
    "\n",
    "Vous en savoir plus sur cette base de donn√©es : http://yann.lecun.com/exdb/mnist/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sous quelle forme se pr√©sentent vos donn√©es ? Que repr√©sentent-elles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour en savoir plus sur les valeurs du dataframe, <a href='https://www.whydomath.org/node/wavlets/imagebasics.html'> petite explication sur l'√©chelle des couleurs</a>.\n",
    "\n",
    "Et en ex√©cutant le code ci-dessous, vous y verrez d√©j√† un peu plus clair üòã "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (np.random.randint(0,270,4)):\n",
    "    img_28_28 = np.array(df.iloc[i, 1:]).reshape(28,28)\n",
    "    plt.title('label: {0}'. format(df.iloc[i, 0]))\n",
    "    plt.imshow(img_28_28, interpolation='antialiased', cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous une 2√®me mani√®re de visualiser le contenu d'une ligne de notre dataframe. Qu'obtenez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in img_28_28:\n",
    "    print(' '.join('{:3}'.format(value) for value in row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le site du MNIST donne plus d'informations sur le traitement men√© sur les images d'origine pour qu'elles aient des formats comparables :\n",
    "\n",
    "> The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.\n",
    "\n",
    "La description est technique mais permet de comprendre que les images qu'on va dessiner nous-m√™mes vont √©galement devoir passer par ce m√™me traitement pour √™tre comparables et donc bien pr√©dites par notre mod√®le."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S√©lection des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a actuellement un dataframe avec 60 000 lignes. Comme vous allez entra√Æner des mod√®les, il est utile de r√©duire la quantit√© de donn√©es qu'on va utiliser ici. Cela risque de r√©duire la qualit√© de pr√©diction mais permet aussi de r√©duire le temps d'entra√Ænement de nos mod√®les. Cr√©ez un dataframe plus l√©ger en ne gardant que 10 000 lignes du dataframe initial.\n",
    "\n",
    "Essayez d'avoir une repr√©sentation homog√®ne de tous les labels que vous allez pr√©dire (soit les chiffres de 0 √† 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, c'est le moment de passer aux choses s√©rieuses ! On va pr√©parer les donn√©es pour le Machine Learning. \n",
    "\n",
    "Apr√®s avoir d√©fini vos variables explicatives et la variable cible, divisez vos donn√©es en jeux d'entra√Ænement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√©rifiez la distribution des labels dans vos deux jeux (par ex. avec un <a href=\"https://seaborn.pydata.org/generated/seaborn.countplot.html\">counplot</a>).\n",
    "\n",
    "Les deux jeux ont-ils des distributions de classe similaires ? Sinon, avez-vous pens√© √† inclure un param√®tre dans le train_test_split qui peut y rem√©dier ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi standardiser vos donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour am√©liorer nos performances et r√©duire le bruit dans nos donn√©es, on peut r√©duire le nombre de variables utilis√©es pour notre ML en faisant une PCA. Faites plusieurs tests pour trouver un nombre de composants qui permet de garder une variance expliqu√©e importante avec un bon score de pr√©cision tout en r√©duisant le temps d'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super ! Vos donn√©es sont pr√™tes. Vous allez pouvoir entra√Æner un mod√®le de Support Vector Machine (SVM). ü§ñ\n",
    "\n",
    "Pour s√©parer les classes, ce mod√®le g√©n√®re un hyperplan dans un espace √† N-dimensions (autant de dimensions que vous avez de variables explicatives) en maximisant l'espace entre l'hyperplan et les support vecteurs (soit les coordonn√©es des points).\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*ZpkLQf2FNfzfH4HXeMw4MQ.png\" />\n",
    "\n",
    "\n",
    "Quelques ressources pour en apprendre plus sur le SVM : \n",
    "*   https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/ \n",
    "*   https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47 \n",
    "*   Le mod√®le est disponible dans <a href=\"https://scikit-learn.org/stable/modules/svm.html\">sklearn</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entra√Ænez un mod√®le en testant plusieurs hyperparam√®tres (par ex. \"kernel\" pour SVM ou \"n_components\" pour la PCA). <a href=\"https://towardsdatascience.com/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d\"> Ici un article utile</a> sur la mani√®re dont on peut choisir le nombre de composantes.\n",
    "\n",
    "Et pourquoi ne pas r√©aliser une GridSearch pour trouver les meilleurs param√®tres ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le meilleur mod√®le identifi√©, vous pouvez le r√©-entrainer en incluant le param√®tre `probability=True` : ce param√®tre permet d'avoir les probabilit√©s de chaque classe dans les pr√©dictions, ce qui sera utile dans la suite de notre travail.\n",
    " \n",
    "Cr√©ez une variable `y_pred` avec les pr√©dictions sur votre jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous avez entrain√© votre mod√®le, on va le tester en pratique sur les images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme au d√©but, on peut afficher plusieurs images de notre jeu de test avec la pr√©diction faite par notre mod√®le. Attention, il faut bien distinguer le `X_test` initial qui contient les 748 champs avec les valeurs des pixels, et notre `X_test` transform√© apr√®s la PCA dont on ne peux plus distinguer les composantes (le code ci-dessous ne fonctionnera que si vous n'avez pas modifi√© le `X_test` initial mais cr√©√© une nouvelle variable en faisant la PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (np.random.randint(0,270,6)):\n",
    "    two_d = (np.reshape(X_test.values[i], (28, 28))).astype(np.uint8)\n",
    "    plt.title('predicted label: {0}'. format(y_pred[i]))\n",
    "    plt.imshow(two_d, interpolation='antialiased', cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez une matrice de confusion. Les r√©sultats vous semblent-ils satisfaisants ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation d'une pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinez le code ci-dessous puis ex√©cutez-le. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.iloc[:, 1:]\n",
    "y = df_sample['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "steps = [('pca', PCA(n_components=.8)), ('svm', SVC(kernel='rbf', probability=True))]\n",
    "pipeline = Pipeline(steps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.score(X_train, y_train))\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cr√©e ici un Pipeline, il s'agit d'une suite d'actions qui permet en une seule ex√©cution de r√©aliser plusieurs traitements √† la suite sur nos donn√©es. \n",
    "\n",
    "Ce pipeline reprend ce qu'on a fait plus haut, √† savoir il applique la PCA puis le mod√®le SVM sur nos donn√©es. Si vous avez standardis√© vos donn√©es, vous pouvez ajouter cette √©tape dans le pipeline. \n",
    "\n",
    "Un pipeline peut aussi √™tre utilis√© pour tester divers hyperparam√®tres sur plusieurs √©tapes d'entra√Ænement du mod√®le (par ex. n_components dans la PCA, hyperparam√®tres du mod√®le) : un exemple concret <a href=\"https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html\"> ici</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir rapidement pr√©dire un label sur de nouvelles donn√©es (soit des chiffres qu'on va dessiner nous-m√™mes !), il est utile de stocker notre mod√®le entra√Æn√© dans un fichier √† partir duquel on pourra directement le charger dans notre application, et ainsi ne pas devoir r√©-entra√Æner notre mod√®le √† chaque fois. \n",
    "\n",
    "Pour cela, on utilise la librairie Pickle qui permet de 's√©rialiser' et de 'd√©s√©rialiser' des objets Python, c'est-√†-dire de stocker dans un format binaire le contenu d'un objet (une liste, un mod√®le...) qu'on peut r√©-importer ensuite.\n",
    "\n",
    "*   Documentation Python sur Pickle (FR) : https://docs.python.org/fr/3/library/pickle.html\n",
    "*   https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "*   https://www.quennec.fr/trucs-astuces/langages/python/python-le-module-pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'digit_classifier.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apr√®s l'ex√©cution de ce code, vous devriez avoir un nouveau fichier `digit_classifier.sav` qui stocke votre mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test des pr√©dictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va tester notre mod√®le enregistr√© sur une des pr√©dictions (1e ligne de X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a 784 colonnes correspondant aux 28x28 pixels de l'image\n",
    "img_test_0 = X_test.iloc[0].values\n",
    "img_test_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute une dimension pour la pr√©diction\n",
    "img_test_0 = np.array(img_test_0).reshape(1, -1) \n",
    "img_test_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la valeur pr√©dite pour la 1√®re ligne de X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On change les dimensions de la 1e ligne pour obtenir une matrice de 28x28\n",
    "img_test_0 = img_test_0.reshape(28, 28)\n",
    "img_test_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi afficher la matrice au format 28x28. Le chiffre pr√©dit apparait-il bien dans cette matrice ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in img_test_0:\n",
    "    print(' '.join('{:3}'.format(value) for value in row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant tenter d'utiliser notre mod√®le pour pr√©dire un chiffre √† partir d'une image qu'il ne connait pas. \n",
    "\n",
    "On teste avec une image sauvegard√©e (`image.jpg`) dont on change la taille au format voulu et r√©-enregistre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"image.jpg\")\n",
    "size = 28, 28\n",
    "\n",
    "print(image.size)\n",
    "image.thumbnail(size,Image.ANTIALIAS)\n",
    "print(image.size)\n",
    "image.save(\"image_28px.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visualise comme avant la nouvelle image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/40727793/how-to-convert-a-grayscale-image-into-a-list-of-pixel-values \n",
    "\n",
    "img = Image.open('image_28px.jpg').convert('L')  # convert image to 8-bit grayscale\n",
    "\n",
    "data = list(img.getdata()) # convert image data to a list of integers\n",
    "# convert that to 2D list (list of lists of integers)\n",
    "data = [data[offset:offset+28] for offset in range(0, 28*28, 28)]\n",
    "\n",
    "for row in data:\n",
    "    print(' '.join('{:3}'.format(value) for value in row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant pouvoir mettre cette image dans le m√™me format que les images du dataset d'entra√Ænement, en reprenant le code de <a href='https://medium.com/@o.kroeger/tensorflow-mnist-and-your-own-handwritten-digits-4d1cd32bbab4'> cet article</a>. \n",
    "\n",
    "Il n'est pas n√©cessaire de comprendre pr√©cis√©ment tout le code mais seulement les grandes √©tapes de ce qu'il permet d'obtenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.array(data)\n",
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace les valeurs basses par des 0\n",
    "gray = np.where(gray > 50, gray, 0)\n",
    "\n",
    "for row in gray:\n",
    "    print(' '.join('{:3}'.format(value) for value in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove every row and column at the sides of the image which are completely black.\n",
    "\n",
    "while np.sum(gray[0]) == 0:\n",
    "    gray = gray[1:]\n",
    "\n",
    "while np.sum(gray[:,0]) == 0:\n",
    "    gray = np.delete(gray,0,1)\n",
    "\n",
    "while np.sum(gray[-1]) == 0:\n",
    "    gray = gray[:-1]\n",
    "\n",
    "while np.sum(gray[:,-1]) == 0:\n",
    "    gray = np.delete(gray,-1,1)\n",
    "\n",
    "rows,cols = gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = gray.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to resize our outer box to fit it into a 20x20 box. We need a resize factor for this.\n",
    "\n",
    "if rows > cols:\n",
    "    factor = 20.0/rows\n",
    "    rows = 20\n",
    "    cols = int(round(cols*factor))\n",
    "    gray = cv2.resize(gray, (cols,rows))\n",
    "else:\n",
    "    factor = 20.0/cols\n",
    "    cols = 20\n",
    "    rows = int(round(rows*factor))\n",
    "    gray = cv2.resize(gray, (cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we need a 28x28 pixel image, we add the missing black rows and columns using the np.lib.pad function which adds 0s to the sides.\n",
    "\n",
    "import math\n",
    "\n",
    "colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the center of mass (function 1), we shift the image so that it is centered (function 2)\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "def getBestShift(img):\n",
    "    cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty\n",
    "\n",
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the functions\n",
    "\n",
    "shiftx,shifty = getBestShift(gray)\n",
    "shifted = shift(gray,shiftx,shifty)\n",
    "gray = shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion au format adapt√©\n",
    "img_flattened = gray.flatten()\n",
    "img_flattened_784 = np.array(img_flattened).reshape(1, -1) \n",
    "img_flattened_784.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche l'image en pixel comme avant\n",
    "\n",
    "data = img_flattened_784.reshape(28, 28)\n",
    "data = data.astype('int64')\n",
    "\n",
    "for row in data:\n",
    "    print(' '.join('{:3}'.format(value) for value in row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu des valeurs des pixels, notre traitement semble avoir march√©, le chiffre est d√©sormais bien centr√©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant pr√©dire la valeur dans l'image ! Votre mod√®le trouve-t-il le bon chiffre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la m√©thode <a href= \"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba\">predict_proba</a>, on peut aussi obtenir la probabilit√© associ√©e √† chaque chiffre (soit les classes pr√©dites). Quel est le degr√© de certitude de votre pr√©diction ? Si le mod√®le a mal pr√©dit le chiffre, la deuxi√®me pr√©diction est-elle bonne ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en pratique : application √† des nouvelles images dessin√©es en direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions\n",
    "\n",
    "Voie rapide : le script Python `classifier.py` contient plusieurs fonctions qui permettent d'appliquer toutes les √©tapes qu'on vient de mener √† de nouvelles donn√©es. \n",
    "\n",
    "Voie longue mais plus ambitieuse : vous pouvez aussi faire ce script vous-m√™mes, par exemple cr√©er une fonction qui applique √† une image fournie en entr√©e le formattage requis pour r√©aliser la pr√©diction et une deuxi√®me fonction qui peut ensuite appliquer le mod√®le enregistr√© √† l'image formatt√©e. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Streamlit\n",
    "\n",
    "Ensuite, ex√©cutez le script app.py avec la commande `streamlit run app.py`. Pour cela vous devrez s√ªrement installer les librairies `streamlit` et `streamlit_drawable_canvas`. \n",
    "\n",
    "Que fait ce script ?  ü§î "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En faisant appel aux fonctions que vous avez d√©finies plus t√¥t, modifiez le script pour pouvoir afficher votre pr√©diction lorsqu'on dessine un chiffre sur le canvas. \n",
    "\n",
    "Pour aller plus loin, vous pouvez maintenant : \n",
    "*   afficher le pourcentage de certitude ou encore le deuxi√®me r√©sultat lorsque la pr√©diction est incertaine ou incorrecte\n",
    "*   stocker les nouvelles images dessin√©es √† la main et recr√©er votre propre base de donn√©es\n",
    "*   d√©couvrir comment entrainer un r√©seau de neurones pour faire la m√™me chose (comme <a href=\"https://data-flair.training/blogs/python-deep-learning-project-handwritten-digit-recognition/\">ici</a> et <a href=\"https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\">ici</a> par exemple) et appliquer ce mod√®le aux images dessin√©es dans votre app. Mais cela vous demandera beaucoup plus de recherche et d'investissement üòâ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autres sources\n",
    "*   https://www.kaggle.com/datasets/oddrationale/mnist-in-csv?select=mnist_train.csv \n",
    "*   https://towardsdatascience.com/support-vector-machine-mnist-digit-classification-with-python-including-my-hand-written-digits-83d6eca7004a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1bb97944e78798a7665c5c17e59dde1c3cccf0074e57674c30db64213d319e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
